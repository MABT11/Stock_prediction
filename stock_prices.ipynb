{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1df8c426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Epoch 1/2\n",
      "84/84 [==============================] - 7s 30ms/step - loss: 0.0070\n",
      "Epoch 2/2\n",
      "84/84 [==============================] - 2s 26ms/step - loss: 0.0013\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mubarak\\AppData\\Local\\Temp\\ipykernel_10024\\3062110377.py:128: FutureWarning: Passing a dict as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  print(actual_data[\"Close\"][prediction_days].values)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['AAPL'], dtype='object', name='Date')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10024\\3062110377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m     \u001b[1;31m# Make predictions for this company\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactual_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction_days\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactual_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Close\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprediction_days\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    982\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 984\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# handle the dup indexing case GH#4246\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_values_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    969\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1192\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1194\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m             \u001b[1;31m# nested tuple slicing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# A collection of keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1132\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1133\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[0;32m   1134\u001b[0m             \u001b[1;33m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1328\u001b[0m         \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m         \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5796\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5854\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5855\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5856\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['AAPL'], dtype='object', name='Date')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from ta.momentum import StochasticOscillator\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.volume import OnBalanceVolumeIndicator\n",
    "from ta.utils import dropna\n",
    "from ta.trend import SMAIndicator, MACD,  WMAIndicator, EMAIndicator\n",
    "from ta.momentum import WilliamsRIndicator, RSIIndicator\n",
    "\n",
    "\n",
    "def get_data(company, start, end):\n",
    "    data = yf.download(company, start=start, end=end)\n",
    "    return data\n",
    "\n",
    "def add_indicators(data):\n",
    "    # Create a new DataFrame with the added indicators\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    rsi_indicator = RSIIndicator(close=df[\"Close\"])\n",
    "    df[\"RSI\"] = rsi_indicator.rsi()\n",
    "    \n",
    "    # Moving Average Convergence Divergence (MACD)\n",
    "    macd_indicator = MACD(close=df[\"Close\"])\n",
    "    df[\"MACD\"] = macd_indicator.macd()\n",
    "    \n",
    "    # Stochastic Oscillator\n",
    "    stochastic_indicator = StochasticOscillator(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "    df[\"%K\"] = stochastic_indicator.stoch()\n",
    "    df[\"%D\"] = stochastic_indicator.stoch_signal()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bb_indicator = BollingerBands(close=df[\"Close\"])\n",
    "    df[\"BB_High\"] = bb_indicator.bollinger_hband()\n",
    "    df[\"BB_Low\"] = bb_indicator.bollinger_lband()\n",
    "    \n",
    "    # On-Balance Volume (OBV)\n",
    "    obv_indicator = OnBalanceVolumeIndicator(close=df[\"Close\"], volume=df[\"Volume\"])\n",
    "    df[\"OBV\"] = obv_indicator.on_balance_volume()\n",
    "    \n",
    "    # Simple Moving Average (SMA)\n",
    "    sma_indicator = SMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"SMA\"] = sma_indicator.sma_indicator()\n",
    "    \n",
    "    # Exponential Moving Average (EMA)\n",
    "    ema_indicator = EMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"EMA\"] = ema_indicator.ema_indicator()\n",
    "    \n",
    "    # Weighted Moving Average (WMA)\n",
    "    wma_indicator = WMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"WMA\"] = wma_indicator.wma()\n",
    "    \n",
    "    # Williams Alligator\n",
    "    williamsr_indicator = WilliamsRIndicator(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "    df[\"WilliamsR\"] = williamsr_indicator.williams_r()\n",
    "    \n",
    "    # Drop any rows with NaN values\n",
    "    df = dropna(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_model(company_data):\n",
    "    # Prepare the data\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaled_data = scaler.fit_transform(company_data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "    prediction_days = 20\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for x in range(prediction_days, len(scaled_data)):\n",
    "        x_train.append(scaled_data[x-prediction_days:x,0])\n",
    "        y_train.append(scaled_data[x,0])\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_train = np.reshape(x_train,(x_train.shape[0], x_train.shape[1],1))\n",
    "\n",
    "    # Build and train the model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True,input_shape=(x_train.shape[1],1)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(x_train, y_train, epochs=2, batch_size=32)\n",
    "\n",
    "    return model, scaler, prediction_days\n",
    "\n",
    "# Define a list of companies and date range to download data\n",
    "companies = [\"AAPL\", \"MSFT\", \"GOOG\"]\n",
    "start = \"2010-03-03\"\n",
    "end = \"2021-01-01\"\n",
    "\n",
    "# Download data for each company and add indicators\n",
    "data = {}\n",
    "models = {}\n",
    "scalers = {}\n",
    "prediction_days = {}\n",
    "for company in companies:\n",
    "    company_data = get_data(company, start, end)\n",
    "    company_data = add_indicators(company_data)\n",
    "    data[company] = company_data\n",
    "\n",
    "    # Train the model for this company\n",
    "    model, scaler, pred_days = train_model(company_data)\n",
    "    models[company] = model\n",
    "    scalers[company] = scaler\n",
    "    prediction_days[company] = pred_days\n",
    "    \n",
    "    # Get actual prices for this company\n",
    "    actual_data = yf.download(company, start=start, end=end)\n",
    "    actual_prices = actual_data[\"Close\"].values\n",
    "\n",
    "    # Make predictions for this company\n",
    "    inputs = actual_data[\"Close\"][-prediction_days:].values\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "    inputs = scaler.transform(inputs)\n",
    "    \n",
    "    X_test = []\n",
    "    for x in range(prediction_days, len(inputs)):\n",
    "        X_test.append(inputs[x-prediction_days:x,0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    predicted_prices = model.predict(X_test)\n",
    "    predicted_prices = scaler.inverse_transform(predicted_prices)\n",
    "    \n",
    "    # Plot actual and predicted prices for this company\n",
    "    plt.plot(actual_prices,color=\"black\",label=f\"Actual {company} prices\")\n",
    "    plt.plot(predicted_prices,color='green',label=f\"predicted {company} prices\")\n",
    "    plt.title(f\"{company} share price\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0123a470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-02 00:00:00\n",
      "2023-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "test_start = dt.datetime(2021,1,2)\n",
    "test_end = dt.datetime(2023,1,1)\n",
    "print(test_start)\n",
    "print(test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03a7a5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Stock: AAPL, R-squared score: -0.00\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Stock: MSFT, R-squared score: -0.01\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Stock: GOOGL, R-squared score: -0.00\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def add_indicators(data):\n",
    "    # Create a new DataFrame with the added indicators\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    rsi_indicator = RSIIndicator(close=df[\"Close\"])\n",
    "    df[\"RSI\"] = rsi_indicator.rsi()\n",
    "    \n",
    "    # Moving Average Convergence Divergence (MACD)\n",
    "    macd_indicator = MACD(close=df[\"Close\"])\n",
    "    df[\"MACD\"] = macd_indicator.macd()\n",
    "    \n",
    "    # Stochastic Oscillator\n",
    "    stochastic_indicator = StochasticOscillator(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "    df[\"%K\"] = stochastic_indicator.stoch()\n",
    "    df[\"%D\"] = stochastic_indicator.stoch_signal()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bb_indicator = BollingerBands(close=df[\"Close\"])\n",
    "    df[\"BB_High\"] = bb_indicator.bollinger_hband()\n",
    "    df[\"BB_Low\"] = bb_indicator.bollinger_lband()\n",
    "    \n",
    "    # On-Balance Volume (OBV)\n",
    "    obv_indicator = OnBalanceVolumeIndicator(close=df[\"Close\"], volume=df[\"Volume\"])\n",
    "    df[\"OBV\"] = obv_indicator.on_balance_volume()\n",
    "    \n",
    "    # Simple Moving Average (SMA)\n",
    "    sma_indicator = SMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"SMA\"] = sma_indicator.sma_indicator()\n",
    "    \n",
    "    # Exponential Moving Average (EMA)\n",
    "    ema_indicator = EMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"EMA\"] = ema_indicator.ema_indicator()\n",
    "    \n",
    "    # Weighted Moving Average (WMA)\n",
    "    wma_indicator = WMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"WMA\"] = wma_indicator.wma()\n",
    "    \n",
    "    # Williams Alligator\n",
    "    williamsr_indicator = WilliamsRIndicator(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "    df[\"WilliamsR\"] = williamsr_indicator.williams_r()\n",
    "    \n",
    "    # Drop any rows with NaN values\n",
    "    df = dropna(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define a list of stock tickers\n",
    "stocks = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "\n",
    "# Loop over the stock tickers and train a model for each one\n",
    "for stock in stocks:\n",
    "    # Load historical stock prices from Yahoo Finance\n",
    "    data = yf.download(stock, start=\"2010-01-01\", end=\"2022-01-01\")\n",
    "    data = add_indicators(data)\n",
    "    # Compute the log returns of the stock prices\n",
    "    data[\"log_return\"] = np.log(data[\"Close\"]).diff()\n",
    "\n",
    "    # Drop any missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_data = data[:len(data)//2]\n",
    "    test_data = data[len(data)//2:]\n",
    "\n",
    "    # Train a linear regression model on the training data\n",
    "    X_train = train_data[[\"log_return\"]]\n",
    "    y_train = train_data[\"log_return\"].shift(-1).fillna(0)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the testing data\n",
    "    X_test = test_data[[\"log_return\"]]\n",
    "    y_test = test_data[\"log_return\"].shift(-1).fillna(0)\n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Stock: {stock}, R-squared score: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60c31104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Stock: AAPL, R-squared score: -0.00\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Stock: MSFT, R-squared score: -0.01\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Stock: GOOGL, R-squared score: -0.01\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def add_indicators(data):\n",
    "    # Create a new DataFrame with the added indicators\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Relative Strength Index (RSI)\n",
    "    rsi_indicator = RSIIndicator(close=df[\"Close\"])\n",
    "    df[\"RSI\"] = rsi_indicator.rsi()\n",
    "    \n",
    "    # Moving Average Convergence Divergence (MACD)\n",
    "    macd_indicator = MACD(close=df[\"Close\"])\n",
    "    df[\"MACD\"] = macd_indicator.macd()\n",
    "    \n",
    "    # Stochastic Oscillator\n",
    "    stochastic_indicator = StochasticOscillator(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "    df[\"%K\"] = stochastic_indicator.stoch()\n",
    "    df[\"%D\"] = stochastic_indicator.stoch_signal()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    bb_indicator = BollingerBands(close=df[\"Close\"])\n",
    "    df[\"BB_High\"] = bb_indicator.bollinger_hband()\n",
    "    df[\"BB_Low\"] = bb_indicator.bollinger_lband()\n",
    "    \n",
    "    # On-Balance Volume (OBV)\n",
    "    obv_indicator = OnBalanceVolumeIndicator(close=df[\"Close\"], volume=df[\"Volume\"])\n",
    "    df[\"OBV\"] = obv_indicator.on_balance_volume()\n",
    "    \n",
    "    # Simple Moving Average (SMA)\n",
    "    sma_indicator = SMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"SMA\"] = sma_indicator.sma_indicator()\n",
    "    \n",
    "    # Exponential Moving Average (EMA)\n",
    "    ema_indicator = EMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"EMA\"] = ema_indicator.ema_indicator()\n",
    "    \n",
    "    # Weighted Moving Average (WMA)\n",
    "    wma_indicator = WMAIndicator(close=df[\"Close\"], window=20)\n",
    "    df[\"WMA\"] = wma_indicator.wma()\n",
    "    \n",
    "    # Williams Alligator\n",
    "    williamsr_indicator = WilliamsRIndicator(high=df[\"High\"], low=df[\"Low\"], close=df[\"Close\"])\n",
    "    df[\"WilliamsR\"] = williamsr_indicator.williams_r()\n",
    "    \n",
    "    # Drop any rows with NaN values\n",
    "    df = dropna(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define a list of stock tickers\n",
    "stocks = [\"AAPL\", \"MSFT\", \"GOOGL\"]\n",
    "\n",
    "# Loop over the stock tickers and train a model for each one\n",
    "for stock in stocks:\n",
    "    # Load historical stock prices from Yahoo Finance\n",
    "    data = yf.download(stock, start=\"2010-01-01\", end=\"2022-01-01\")\n",
    "    #data = add_indicators(data)\n",
    "    # Compute the log returns of the stock prices\n",
    "    data[\"log_return\"] = np.log(data[\"Close\"]).diff()\n",
    "\n",
    "    # Drop any missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_data = data[:len(data)//2]\n",
    "    test_data = data[len(data)//2:]\n",
    "\n",
    "    # Train a linear regression model on the training data\n",
    "    X_train = train_data[[\"log_return\"]]\n",
    "    y_train = train_data[\"log_return\"].shift(-1).fillna(0)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the testing data\n",
    "    X_test = test_data[[\"log_return\"]]\n",
    "    y_test = test_data[\"log_return\"].shift(-1).fillna(0)\n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Stock: {stock}, R-squared score: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5cf76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
